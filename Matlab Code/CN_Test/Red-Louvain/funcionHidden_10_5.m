function [y1] = myNeuralNetworkFunction(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 26-Jan-2021 20:51:49.
% 
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = 23xQ matrix, input #1
% and returns:
%   y = 1xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0];
x1_step1.gain = [0.166666666666667;0.333333333333333;0.666666666666667;0.222222222222222;0.0952380952380952;2;0.5;2;2;2;2;0.666666666666667;0.333333333333333;0.166666666666667;0.2;1;0.4;0.2;2;2;2;2;3.06849315203002];
x1_step1.ymin = -1;

% Layer 1
b1 = [-0.0085928189511277116436;0.050417192692103540708;-0.20502739955930604498;0.3849129881125689101;0.034617902276182631327;-0.19336474273921222533;0.59412506746614679454;0.18035001543402770507;-0.131930006239873443;-0.23158600316843450106];
IW1_1 = [0.090287156550516944886 -0.22089978944084523449 -0.040254339528573296336 -0.41213907162109864046 -0.48114931550917766634 0.27026427955435566863 -1.1491630490702315903 0.041430044585596972895 -0.12061160552807562163 0.13853476239986711738 0.025784686027382330148 0.63588205402480002526 0.77849030772514371534 0.19059002975348202091 -0.36877504432336499773 -0.39071262093042796737 0.24760888648885329144 -0.40888577777814932857 -0.14468995847858387438 -0.24439076115076485696 0.077242518108832133872 0.18519453109073974462 -0.44564432080769489364;0.1881111378200576445 0.7266619157605318513 0.96657727587396125024 0.27333637496705132097 0.1333564635832103773 0.25931348179958846334 -1.1464451009558798145 0.017636685943741878951 -0.36801519574397179024 -0.0014329372362536561911 -0.24085570126694394455 -0.37615574797998013734 0.28555787373148033836 0.18231031652099002893 -0.37246409059501378591 -0.16318007182691046664 1.1679584891013725656 -0.59878356328302118072 0.47958657262383963538 -0.50226834772277462182 -0.25158580305316524672 -0.22155654922748463376 -0.34939106708874573259;-0.14899850586691579246 -0.21080246436537272703 0.033109885924662525725 -0.60808936176922978589 0.9836967243631022928 0.12398325444576510646 0.79077211908024125364 -0.14489961896613506864 0.015204463744083683216 -0.20302242196539393992 0.23122494909155191789 -0.72382808147323218773 -0.70328433014722890881 -0.31924984788555266224 0.091682313595434453135 0.069982629101736568145 0.16027471447363994539 -0.28950885931515091265 -0.22715983748664347885 0.23586555291510641341 0.079849402368161695454 -0.22876923581434399635 -0.89470602951639810474;0.18286759263499013928 0.095109942005293462985 -0.27723144914251351967 0.99345429105366522826 0.39303153699660492437 0.11004372546488123963 0.58089558045455780277 0.11382646264461092345 -0.17163013327991497037 -0.26422692884531079338 0.18271281123152327552 0.62185850778306128728 -1.1747549776825065848 0.37153433491189730153 0.33544395243646379923 -0.81784649204122927824 -0.4937117257928074765 -0.42391523751810045173 0.3690533576641168434 0.13623593959566870915 -0.15672030569830505686 -0.097629959454802961449 0.11648118088386190394;-0.51528372760632412675 0.48913107701521280068 -0.41654396547155991826 0.71616903452903457605 0.10008612342205569501 0.25895854597824197185 -0.80191309272231903194 0.10452174210393372356 0.042914680186541688534 -0.042472260985983278925 -0.056503020975351696265 0.7484940048815558189 1.2475344074852292575 0.26733589575736582677 -0.40482111634953921175 -0.52203988086981933936 0.20867529991938094103 0.33267007090759792565 -0.10284951062530610366 -0.039437403190288274069 -0.061620560664023583952 -0.055023376542137805711 1.6926636129060999014;0.60740851814024499067 0.10939920008394236894 0.41517769987720781755 -0.0010498976506111005243 -1.5579776148314594675 0.043971422179758461179 -0.40232190820132451847 0.13447316165921871511 0.13271196314010499928 0.13981825147582976898 -0.15628725322803219133 1.2054391772404435823 -0.91340537197298776739 -0.52087709462504283575 -0.027709571985984733644 0.2282792483246856019 -0.33840890375543891677 -0.23380229163134963466 0.36174425942224286423 -0.092758108150788207147 0.15977036563381033507 0.09632962905918299179 -0.8013754765116363199;-0.31266760729361464666 0.034247470543579024149 0.089080909699357474496 0.93763292029511702275 0.66832246167625619648 0.51714641838052799461 -0.10223221599606556464 0.22115062173188468342 -0.081349921027098995308 -0.1488004019536491862 -0.14573120591492158549 -0.79683740318498141875 0.21229662265188314896 -0.12907792179333682503 0.094969183375576290973 0.62992448610309470514 0.70089873536549751609 0.14823535355732989083 0.055816967367292545654 -0.42753297826202152354 -0.27889849351468387617 -0.56844348166056168914 -0.47808105643632337056;-0.25296826139969391667 0.23508839693429653406 0.24492928406616926162 0.059363932829723860263 -1.299519307863718609 0.073190306793018883313 -0.32757452434977973876 -0.071822308179083027557 -0.057529024344610608932 -0.19199652972572056608 -0.24559753182913840464 0.13538351486696806325 0.58542783356775707215 0.54047936908156823943 -0.24291576540261536343 -0.044018218520863787446 -0.57956944442738689283 0.091144031176494430535 0.00083247804321306972681 -0.11076261676534690515 -0.26651161575627446698 -0.089135169743202333215 -0.9883173008087988709;0.035184872986665130523 -0.1389993921735948601 -0.96831386131647012583 0.67486273964654552859 -0.033644639395382890112 0.36536165039407897392 -0.27714616613315534721 0.063475719849797218597 -0.024060534864823006351 -0.1054291419073081354 0.08492486513761045297 -0.26697201191408259646 0.38715654662218951243 -0.11983849869598563187 -0.51935282741396959771 -0.095449902718544643587 -0.28260628370496537753 0.27175273262498100824 0.06289816824377200688 0.17563681707029343837 0.087795117046697124241 0.014335891638666865833 0.72534884002985711149;-0.42754461345355726509 -0.041361218609810339319 0.19261274023904084718 0.74532965426515951357 0.050547332433146754949 0.083831632207813755464 0.047628135225004905595 0.40832228726522629136 -0.12188667284613625974 -0.029716322446464112084 -0.0239720704453079414 0.23105423849757922294 0.18973850104532652416 -0.2320859855120106785 0.55590737771886256091 -0.45510935539063829269 -0.17663790849165517116 -0.65184334590390247133 0.054534541699087439592 0.085903035458323423468 -0.066544033016273637648 0.045907581084673763916 -0.11933432956549409887];

% Layer 2
b2 = -0.34954321368754526222;
LW2_1 = [1.4336298275751708786 -1.4474067698461476894 -1.6641214174616891786 1.4551348354882172043 -1.1449515769777878216 -0.99898773205903323991 1.8499781947050328856 -0.96990357587336795131 -1.4470389797246863139 -1.1918257911799385873];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 0.0196656833824975;
y1_step1.xoffset = 0;

% ===== SIMULATION ========

% Dimensions
Q = size(x1,2); % samples

% Input 1
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = repmat(b2,1,Q) + LW2_1*a1;

% Output 1
y1 = mapminmax_reverse(a2,y1_step1);
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
